{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Model-Instantiation\" data-toc-modified-id=\"Model-Instantiation-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Model Instantiation</a></span></li><li><span><a href=\"#Model-prep-and-Train/Test-split\" data-toc-modified-id=\"Model-prep-and-Train/Test-split-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Model prep and Train/Test split</a></span></li><li><span><a href=\"#CountVectorizer-(Transform-text-to-vectors)\" data-toc-modified-id=\"CountVectorizer-(Transform-text-to-vectors)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>CountVectorizer (Transform text to vectors)</a></span></li><li><span><a href=\"#Fit-Data\" data-toc-modified-id=\"Fit-Data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Fit Data</a></span></li><li><span><a href=\"#Modeling-Score\" data-toc-modified-id=\"Modeling-Score-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Modeling Score</a></span></li><li><span><a href=\"#Model-Score-for-MD-alone\" data-toc-modified-id=\"Model-Score-for-MD-alone-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Model Score for MD alone</a></span></li><li><span><a href=\"#Model-Score-for-QA-alone\" data-toc-modified-id=\"Model-Score-for-QA-alone-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Model Score for QA alone</a></span></li><li><span><a href=\"#Tesla-Only\" data-toc-modified-id=\"Tesla-Only-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Tesla Only</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import pandas_datareader as pdr\n",
    "\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingRegressor, VotingClassifier, RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier,   AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "\n",
    "from capstone_function import model_scores\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "df = pickle.load( open( \"../data/df_words_target.pkl\", \"rb\" ) )\n",
    "df.drop_duplicates(subset='transcripts', keep='first', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class Balance for Target Value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.pct_price_target.value_counts(normalize=True).plot(kind='bar',title='Class Balance: Stock is up next day = 1 | Down =0');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_lemmatizer (text): \n",
    "    '''\n",
    "    Initializing tokenizer and lemmatizer to handle NLP preprocessing. \n",
    "    1. breakdown the word by alphanumeric characters and dollar with number\n",
    "    2. Create a list that appended with lemmatized posts and rejoin words by one string \n",
    "       alongside removing characters and numbers\n",
    "    '''\n",
    "    \n",
    "    tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]+|\\S+')\n",
    "    tokens = [tokenizer.tokenize(post.lower()) for post in (df[text])]\n",
    "    \n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lems = []\n",
    "    for post in tokens:\n",
    "        tok_post = []\n",
    "        for word in post:\n",
    "            tok_post.append(lemmatizer.lemmatize(word)) #Remove non-letter\n",
    "            #tok_post.append(re.sub(\"[^a-zA-Z]\", \"\", lemmatizer.lemmatize(word)))\n",
    "\n",
    "        posts = \" \".join(tok_post)        \n",
    "        lems.append(posts)\n",
    "        \n",
    "    \n",
    "    words_not_used = [ 'reeve musk', 'tesla', 'general motor', 'ha', 'don']\n",
    "    \n",
    "    lems = [w for w in lems if not w in words_not_used] #stopwords.words('english')\n",
    "    \n",
    "\n",
    "    df[text] = lems #overwrite the df\n",
    "    \n",
    "    print (f'tokenizer processed: {len(tokens)}')\n",
    "    print (f'lemmatizer processed: {len(lems)}')\n",
    "    #return lems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer processed: 61\n",
      "lemmatizer processed: 61\n",
      "tokenizer processed: 61\n",
      "lemmatizer processed: 61\n",
      "tokenizer processed: 61\n",
      "lemmatizer processed: 61\n"
     ]
    }
   ],
   "source": [
    "tokenizer_lemmatizer('transcripts')\n",
    "tokenizer_lemmatizer('tx_MD')\n",
    "tokenizer_lemmatizer('tx_QA')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "et = ExtraTreesClassifier(random_state=42)\n",
    "ada = AdaBoostClassifier(random_state=42)\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "xb = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "svm = SVC (kernel='poly', degree=2)\n",
    "clf = SVC(gamma='scale')\n",
    "svc = LinearSVC()\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Emsenble models with specific parameters\n",
    "evc = VotingClassifier( estimators=[ ('lr',logreg), ('dt', dt), ('svm', svm),('et',et) ], voting='hard')\n",
    "rf1 = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "xb1 = xgb.XGBClassifier(learning_rate =0.1,n_estimators=1000,max_depth=5,min_child_weight=1,gamma=0,subsample=0.8,colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',nthread=4,scale_pos_weight=1,seed=42)\n",
    "ada1 = AdaBoostClassifier (DecisionTreeClassifier(), n_estimators=10, learning_rate=1, random_state= 42 )\n",
    "bg = BaggingClassifier(DecisionTreeClassifier(), max_samples=0.5, max_features=1,n_estimators=10,random_state= 42 )\n",
    "evc1 = VotingClassifier( estimators=[ ('svc',svc),('clf',clf), ('et', et), ('xb', xb),('gb',gb) ], voting='hard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model prep and Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text for transcripts\n",
    "X = df['transcripts']\n",
    "y = df['pct_price_target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text for MD\n",
    "X_1 = df['tx_MD']\n",
    "y_1 = df['pct_price_target']\n",
    "\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_1, y_1, random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text for MD\n",
    "X_2 = df['tx_QA']\n",
    "y_2 = df['pct_price_target']\n",
    "\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer (Transform text to vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_not_use = stopwords.words('english')\n",
    "\n",
    "words_not_use.extend(\n",
    "['like', 'did', 'just', 've', 'people', 'time', 'tesla', 'feel', \n",
    " 'want', 'thing', 'think', 'yes', 'still','yeah','pretty','knock', 'knowledge', \n",
    " 'kong', 'laborious', 'laced','lacking', 'laid', 'zonei'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use default options for CountVectorizer.\n",
    "vect = CountVectorizer(analyzer = \"word\",\n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None,\n",
    "                             stop_words = words_not_use, ngram_range=(1, 1))\n",
    "\n",
    "\n",
    "vect2 = CountVectorizer(analyzer = \"word\",\n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None,\n",
    "                             stop_words = words_not_use, ngram_range=(2, 2))\n",
    "\n",
    "vect3 = CountVectorizer(analyzer = \"word\",\n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None,\n",
    "                             stop_words = words_not_use, ngram_range=(3, 3))\n",
    "\n",
    "tvec = TfidfVectorizer(analyzer = \"word\",\n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None,\n",
    "                             stop_words = words_not_use) \n",
    "\n",
    "tvec2 = TfidfVectorizer(analyzer = \"word\",\n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None,\n",
    "                             stop_words = words_not_use,  ngram_range=(2, 2)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer\n",
    "X_train_vect = vect.fit_transform(X_train)\n",
    "X_test_vect = vect.transform(X_test)\n",
    "\n",
    "X_train_vect2 = vect2.fit_transform(X_train)\n",
    "X_test_vect2 = vect2.transform(X_test)\n",
    "\n",
    "X_train_vect3 = vect3.fit_transform(X_train)\n",
    "X_test_vect3 = vect3.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF\n",
    "X_train_tvec = tvec.fit_transform(X_train)\n",
    "X_test_tvec = tvec.transform(X_test)\n",
    "\n",
    "X_train_tvec2 = tvec2.fit_transform(X_train)\n",
    "X_test_tvec2 = tvec2.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy score</th>\n",
       "      <th>cv train score</th>\n",
       "      <th>cv test score</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "      <th>train-test gap</th>\n",
       "      <th>model status</th>\n",
       "      <th>bias vs variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.335714</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.375794</td>\n",
       "      <td>0.255556</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>-0.087500</td>\n",
       "      <td>underfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.555754</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.140278</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.536310</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.352778</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.531944</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.467857</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.448611</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.398214</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC(C=1.0, class_weight=None, dual=True,...</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.356548</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC(C=1.0, cache_size=200, class_weight=None, ...</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.485913</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.348611</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.404167</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.380159</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VotingClassifier(estimators=[('lr', LogisticRe...</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  accuracy score  \\\n",
       "0  LogisticRegression(C=1.0, class_weight=None, d...          0.7500   \n",
       "0  KNeighborsClassifier(algorithm='auto', leaf_si...          0.6875   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...          0.4375   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...          0.6250   \n",
       "0  (ExtraTreeClassifier(class_weight=None, criter...          0.6250   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...          0.6250   \n",
       "0  ([DecisionTreeRegressor(criterion='friedman_ms...          0.6250   \n",
       "0  MultinomialNB(alpha=1.0, class_prior=None, fit...          0.6875   \n",
       "0  LinearSVC(C=1.0, class_weight=None, dual=True,...          0.7500   \n",
       "0  SVC(C=1.0, cache_size=200, class_weight=None, ...          0.5625   \n",
       "0  XGBClassifier(base_score=0.5, booster='gbtree'...          0.8125   \n",
       "0  XGBClassifier(base_score=0.5, booster='gbtree'...          0.6875   \n",
       "0  VotingClassifier(estimators=[('lr', LogisticRe...          0.6875   \n",
       "\n",
       "   cv train score  cv test score  train score  test score  train-test gap  \\\n",
       "0        0.335714       0.566667     1.000000      0.7500        0.250000   \n",
       "0        0.375794       0.255556     0.600000      0.6875       -0.087500   \n",
       "0        0.555754       0.566667     0.577778      0.4375        0.140278   \n",
       "0        0.536310       0.366667     0.977778      0.6250        0.352778   \n",
       "0        0.531944       0.566667     1.000000      0.6250        0.375000   \n",
       "0        0.467857       0.577778     1.000000      0.6250        0.375000   \n",
       "0        0.448611       0.500000     1.000000      0.6250        0.375000   \n",
       "0        0.398214       0.377778     1.000000      0.6875        0.312500   \n",
       "0        0.356548       0.566667     1.000000      0.7500        0.250000   \n",
       "0        0.485913       0.500000     0.911111      0.5625        0.348611   \n",
       "0        0.404167       0.566667     1.000000      0.8125        0.187500   \n",
       "0        0.380159       0.622222     1.000000      0.6875        0.312500   \n",
       "0        0.511111       0.500000     1.000000      0.6875        0.312500   \n",
       "\n",
       "  model status bias vs variance  \n",
       "0      overfit    high variance  \n",
       "0     underfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer\n",
    "sm = pd.DataFrame() # Instantiate the empty shell to hold the function\n",
    "models = [logreg, knn, bg, rf, et, ada, gb, nb, svc, clf, xb,xb1,evc]\n",
    "\n",
    "for i in models:\n",
    "    sm = sm.append(model_scores(i, X_train_vect, y_train, X_test_vect, y_test))\n",
    "sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy score</th>\n",
       "      <th>cv train score</th>\n",
       "      <th>cv test score</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "      <th>train-test gap</th>\n",
       "      <th>model status</th>\n",
       "      <th>bias vs variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.288095</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.015278</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.555754</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.206944</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.624008</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.555952</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.423611</td>\n",
       "      <td>0.255556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.555754</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>-0.006944</td>\n",
       "      <td>underfit</td>\n",
       "      <td>high bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC(C=1.0, class_weight=None, dual=True,...</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.335714</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.227778</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC(C=1.0, cache_size=200, class_weight=None, ...</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.555754</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>-0.006944</td>\n",
       "      <td>underfit</td>\n",
       "      <td>high bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.424802</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.467857</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VotingClassifier(estimators=[('lr', LogisticRe...</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.533532</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  accuracy score  \\\n",
       "0  LogisticRegression(C=1.0, class_weight=None, d...          0.5625   \n",
       "0  KNeighborsClassifier(algorithm='auto', leaf_si...          0.5625   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...          0.4375   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...          0.6250   \n",
       "0  (ExtraTreeClassifier(class_weight=None, criter...          0.5625   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...          0.5625   \n",
       "0  ([DecisionTreeRegressor(criterion='friedman_ms...          0.5625   \n",
       "0  MultinomialNB(alpha=1.0, class_prior=None, fit...          0.5625   \n",
       "0  LinearSVC(C=1.0, class_weight=None, dual=True,...          0.7500   \n",
       "0  SVC(C=1.0, cache_size=200, class_weight=None, ...          0.5625   \n",
       "0  XGBClassifier(base_score=0.5, booster='gbtree'...          0.6250   \n",
       "0  XGBClassifier(base_score=0.5, booster='gbtree'...          0.7500   \n",
       "0  VotingClassifier(estimators=[('lr', LogisticRe...          0.5625   \n",
       "\n",
       "   cv train score  cv test score  train score  test score  train-test gap  \\\n",
       "0        0.487500       0.500000     0.666667      0.5625        0.104167   \n",
       "0        0.288095       0.433333     0.577778      0.5625        0.015278   \n",
       "0        0.555754       0.566667     0.644444      0.4375        0.206944   \n",
       "0        0.487500       0.444444     1.000000      0.6250        0.375000   \n",
       "0        0.624008       0.622222     1.000000      0.5625        0.437500   \n",
       "0        0.555952       0.311111     1.000000      0.5625        0.437500   \n",
       "0        0.423611       0.255556     1.000000      0.5625        0.437500   \n",
       "0        0.555754       0.433333     0.555556      0.5625       -0.006944   \n",
       "0        0.335714       0.366667     0.977778      0.7500        0.227778   \n",
       "0        0.555754       0.566667     0.555556      0.5625       -0.006944   \n",
       "0        0.424802       0.422222     1.000000      0.6250        0.375000   \n",
       "0        0.467857       0.366667     1.000000      0.7500        0.250000   \n",
       "0        0.533532       0.500000     0.666667      0.5625        0.104167   \n",
       "\n",
       "  model status bias vs variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0     underfit        high bias  \n",
       "0      overfit    high variance  \n",
       "0     underfit        high bias  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDF\n",
    "sm = pd.DataFrame() # Instantiate the empty shell to hold the function\n",
    "models = [logreg, knn, bg, rf, et, ada, gb, nb, svc, clf, xb,xb1,evc]\n",
    "\n",
    "for i in models:\n",
    "    sm = sm.append(model_scores(i, X_train_tvec, y_train, X_test_tvec, y_test))\n",
    "sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below sections show three attempts of using different ngrams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy score</th>\n",
       "      <th>cv train score</th>\n",
       "      <th>cv test score</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "      <th>train-test gap</th>\n",
       "      <th>model status</th>\n",
       "      <th>bias vs variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.404167</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  accuracy score  \\\n",
       "0  XGBClassifier(base_score=0.5, booster='gbtree'...          0.8125   \n",
       "\n",
       "   cv train score  cv test score  train score  test score  train-test gap  \\\n",
       "0        0.404167       0.566667          1.0      0.8125          0.1875   \n",
       "\n",
       "  model status bias vs variance  \n",
       "0      overfit    high variance  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = pd.DataFrame() # Instantiate the empty shell to hold the function\n",
    "models = [xb]\n",
    "\n",
    "for i in models:\n",
    "    sm = sm.append(model_scores(i, X_train_vect, y_train, X_test_vect, y_test))\n",
    "sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use of unigram**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the use the unigram provides a good score in the model, it doesn't hint any clue on the financial fundamental. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>answer</td>\n",
       "      <td>0.069572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5595</th>\n",
       "      <td>pre</td>\n",
       "      <td>0.052077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>bit</td>\n",
       "      <td>0.049155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>buy</td>\n",
       "      <td>0.048137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6293</th>\n",
       "      <td>respond</td>\n",
       "      <td>0.048111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754</th>\n",
       "      <td>enough</td>\n",
       "      <td>0.046701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7622</th>\n",
       "      <td>transfer</td>\n",
       "      <td>0.039443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6600</th>\n",
       "      <td>seasonally</td>\n",
       "      <td>0.032673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3108</th>\n",
       "      <td>field</td>\n",
       "      <td>0.032455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7226</th>\n",
       "      <td>successful</td>\n",
       "      <td>0.031414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature      coef\n",
       "751       answer  0.069572\n",
       "5595         pre  0.052077\n",
       "1151         bit  0.049155\n",
       "1328         buy  0.048137\n",
       "6293     respond  0.048111\n",
       "2754      enough  0.046701\n",
       "7622    transfer  0.039443\n",
       "6600  seasonally  0.032673\n",
       "3108       field  0.032455\n",
       "7226  successful  0.031414"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df = pd.DataFrame()\n",
    "feature_importance_df['feature'] = vect.get_feature_names()\n",
    "feature_importance_df['coef'] = xb.feature_importances_\n",
    "feature_importance_df.sort_values(by='coef', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use of bigrams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy score</th>\n",
       "      <th>cv train score</th>\n",
       "      <th>cv test score</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "      <th>train-test gap</th>\n",
       "      <th>model status</th>\n",
       "      <th>bias vs variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.450198</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  accuracy score  \\\n",
       "0  XGBClassifier(base_score=0.5, booster='gbtree'...          0.5625   \n",
       "\n",
       "   cv train score  cv test score  train score  test score  train-test gap  \\\n",
       "0        0.450198       0.388889          1.0      0.5625          0.4375   \n",
       "\n",
       "  model status bias vs variance  \n",
       "0      overfit    high variance  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = pd.DataFrame() # Instantiate the empty shell to hold the function\n",
    "models = [xb]\n",
    "\n",
    "for i in models:\n",
    "    sm = sm.append(model_scores(i, X_train_vect2, y_train, X_test_vect2, y_test))\n",
    "sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62092</th>\n",
       "      <td>inventory level</td>\n",
       "      <td>0.082186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92540</th>\n",
       "      <td>profit margin</td>\n",
       "      <td>0.064869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81897</th>\n",
       "      <td>okay thanks</td>\n",
       "      <td>0.063759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64200</th>\n",
       "      <td>kind get</td>\n",
       "      <td>0.052793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129128</th>\n",
       "      <td>well obviously</td>\n",
       "      <td>0.051053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16282</th>\n",
       "      <td>billion liquidity</td>\n",
       "      <td>0.050934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118463</th>\n",
       "      <td>team really</td>\n",
       "      <td>0.050461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131269</th>\n",
       "      <td>would something</td>\n",
       "      <td>0.040631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38869</th>\n",
       "      <td>emmanuel rosner</td>\n",
       "      <td>0.038515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9561</th>\n",
       "      <td>america merrill</td>\n",
       "      <td>0.031743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  feature      coef\n",
       "62092     inventory level  0.082186\n",
       "92540       profit margin  0.064869\n",
       "81897         okay thanks  0.063759\n",
       "64200            kind get  0.052793\n",
       "129128     well obviously  0.051053\n",
       "16282   billion liquidity  0.050934\n",
       "118463        team really  0.050461\n",
       "131269    would something  0.040631\n",
       "38869     emmanuel rosner  0.038515\n",
       "9561      america merrill  0.031743"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDF \n",
    "feature_importance_df = pd.DataFrame()\n",
    "feature_importance_df['feature'] = tvec2.get_feature_names()\n",
    "feature_importance_df['coef'] = xb.feature_importances_\n",
    "feature_importance_df.sort_values(by='coef', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use of trigram**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of trigram doesn't provide any benefit to the model as suggested by the ROC curve; it is even worst than the baseline. Besides, trigram doesn't suggest any key phrase that may impact the the operation efficiency during the conversation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy score</th>\n",
       "      <th>cv train score</th>\n",
       "      <th>cv test score</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "      <th>train-test gap</th>\n",
       "      <th>model status</th>\n",
       "      <th>bias vs variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.62123</td>\n",
       "      <td>0.455556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  accuracy score  \\\n",
       "0  XGBClassifier(base_score=0.5, booster='gbtree'...          0.3125   \n",
       "\n",
       "   cv train score  cv test score  train score  test score  train-test gap  \\\n",
       "0         0.62123       0.455556          1.0      0.3125          0.6875   \n",
       "\n",
       "  model status bias vs variance  \n",
       "0      overfit    high variance  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = pd.DataFrame() # Instantiate the empty shell to hold the function\n",
    "models = [xb]\n",
    "\n",
    "for i in models:\n",
    "    sm = sm.append(model_scores(i, X_train_vect3, y_train, X_test_vect3, y_test))\n",
    "sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70473</th>\n",
       "      <td>full year basis</td>\n",
       "      <td>0.058089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115855</th>\n",
       "      <td>motor co thank</td>\n",
       "      <td>0.054882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19973</th>\n",
       "      <td>barclays capital inc</td>\n",
       "      <td>0.054147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73441</th>\n",
       "      <td>give little bit</td>\n",
       "      <td>0.049418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71692</th>\n",
       "      <td>general motor co</td>\n",
       "      <td>0.046887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13842</th>\n",
       "      <td>america north america</td>\n",
       "      <td>0.043735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200519</th>\n",
       "      <td>year would expect</td>\n",
       "      <td>0.042183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92925</th>\n",
       "      <td>johnson barclays please</td>\n",
       "      <td>0.036333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147525</th>\n",
       "      <td>really well positioned</td>\n",
       "      <td>0.035625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32998</th>\n",
       "      <td>chief financial officer</td>\n",
       "      <td>0.034373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        feature      coef\n",
       "70473           full year basis  0.058089\n",
       "115855           motor co thank  0.054882\n",
       "19973      barclays capital inc  0.054147\n",
       "73441           give little bit  0.049418\n",
       "71692          general motor co  0.046887\n",
       "13842     america north america  0.043735\n",
       "200519        year would expect  0.042183\n",
       "92925   johnson barclays please  0.036333\n",
       "147525   really well positioned  0.035625\n",
       "32998   chief financial officer  0.034373"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df = pd.DataFrame()\n",
    "feature_importance_df['feature'] = vect3.get_feature_names()\n",
    "feature_importance_df['coef'] = xb.feature_importances_\n",
    "feature_importance_df.sort_values(by='coef', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a15aceeb8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "y_pred_prob = xb1.predict_proba(X_test_tvec2)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# create plot\n",
    "plt.plot(fpr, tpr, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random guess')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.xlim([-0.02, 1])\n",
    "plt.ylim([0, 1.02])\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Score for MD alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "X = df['tx_MD']\n",
    "y = df['pct_price_target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)\n",
    "\n",
    "\n",
    "# Create document-term matrices.\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "# Use Naive Bayes to predict the star rating.\n",
    "\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "\n",
    "# Calculate accuracy.\n",
    "print((metrics.accuracy_score(y_test, y_pred_class)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy score</th>\n",
       "      <th>cv train score</th>\n",
       "      <th>cv test score</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "      <th>train-test gap</th>\n",
       "      <th>model status</th>\n",
       "      <th>bias vs variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.441270</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.444246</td>\n",
       "      <td>0.255556</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.468056</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  accuracy score  \\\n",
       "0  LogisticRegression(C=1.0, class_weight=None, d...           0.625   \n",
       "0  MultinomialNB(alpha=1.0, class_prior=None, fit...           0.750   \n",
       "0  XGBClassifier(base_score=0.5, booster='gbtree'...           0.625   \n",
       "\n",
       "   cv train score  cv test score  train score  test score  train-test gap  \\\n",
       "0        0.441270       0.366667     1.000000       0.625        0.375000   \n",
       "0        0.444246       0.255556     0.933333       0.750        0.183333   \n",
       "0        0.468056       0.311111     1.000000       0.625        0.375000   \n",
       "\n",
       "  model status bias vs variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = pd.DataFrame() # Instantiate the empty shell to hold the function\n",
    "models = [logreg,nb, xb]\n",
    "\n",
    "for i in models:\n",
    "    sm = sm.append(model_scores(i, X_train_dtm, y_train, X_test_dtm, y_test))\n",
    "sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Score for QA alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6875\n"
     ]
    }
   ],
   "source": [
    "# Use default options for CountVectorizer.\n",
    "vect = CountVectorizer(analyzer = \"word\",\n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None,\n",
    "                             stop_words = 'english', ngram_range=(2, 2))\n",
    "\n",
    "\n",
    "X = df['tx_QA']\n",
    "y = df['pct_price_target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)\n",
    "\n",
    "\n",
    "# Create document-term matrices.\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "# Use Naive Bayes to predict the star rating.\n",
    "\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "\n",
    "# Calculate accuracy.\n",
    "print((metrics.accuracy_score(y_test, y_pred_class)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy score</th>\n",
       "      <th>cv train score</th>\n",
       "      <th>cv test score</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "      <th>train-test gap</th>\n",
       "      <th>model status</th>\n",
       "      <th>bias vs variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.400992</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.375794</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.491865</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  accuracy score  \\\n",
       "0  LogisticRegression(C=1.0, class_weight=None, d...          0.6875   \n",
       "0  MultinomialNB(alpha=1.0, class_prior=None, fit...          0.6875   \n",
       "0  XGBClassifier(base_score=0.5, booster='gbtree'...          0.5625   \n",
       "\n",
       "   cv train score  cv test score  train score  test score  train-test gap  \\\n",
       "0        0.400992       0.377778          1.0      0.6875          0.3125   \n",
       "0        0.375794       0.433333          1.0      0.6875          0.3125   \n",
       "0        0.491865       0.366667          1.0      0.5625          0.4375   \n",
       "\n",
       "  model status bias vs variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = pd.DataFrame() # Instantiate the empty shell to hold the function\n",
    "models = [logreg,nb, xb]\n",
    "\n",
    "for i in models:\n",
    "    sm = sm.append(model_scores(i, X_train_dtm, y_train, X_test_dtm, y_test))\n",
    "sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tesla Only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running one company provided a high score than combined all automaker in the U.S; however, overfitting still exists. Surprisingly, NB has a higher score than XGBoost. Due to the small data set, NB seems to performance better in terms of computing power and accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "df = pickle.load( open( \"../data/df_1.pkl\", \"rb\" ) )\n",
    "\n",
    "df.drop_duplicates(subset='transcripts', keep='first', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer processed: 15\n",
      "lemmatizer processed: 15\n"
     ]
    }
   ],
   "source": [
    "tokenizer_lemmatizer('transcripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_not_use = stopwords.words('english')\n",
    "words_not_use.extend(\n",
    "['like', 'did', 'just', 've', 'people', 'time', 'tesla', 'feel', \n",
    " 'want', 'thing', 'think', 'yes', 'still','yeah','pretty','knock', 'knowledge', \n",
    " 'kong', 'laborious', 'laced','lacking', 'laid', 'zonei'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text for transcripts\n",
    "X = df['transcripts']\n",
    "y = df['pct_price_target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use default options for CountVectorizer.\n",
    "vect = CountVectorizer(analyzer = \"word\",\n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None,\n",
    "                             stop_words = words_not_use, ngram_range=(1, 1))\n",
    "\n",
    "\n",
    "vect2 = CountVectorizer(analyzer = \"word\",\n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None,\n",
    "                             stop_words = words_not_use, ngram_range=(2, 2))\n",
    "\n",
    "vect3 = CountVectorizer(analyzer = \"word\",\n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None,\n",
    "                             stop_words = words_not_use, ngram_range=(3, 3))\n",
    "\n",
    "tvec = TfidfVectorizer(analyzer = \"word\",\n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None,\n",
    "                             stop_words = words_not_use) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer\n",
    "X_train_vect = vect.fit_transform(X_train)\n",
    "X_test_vect = vect.transform(X_test)\n",
    "\n",
    "X_train_vect2 = vect2.fit_transform(X_train)\n",
    "X_test_vect2 = vect2.transform(X_test)\n",
    "\n",
    "X_train_vect3 = vect3.fit_transform(X_train)\n",
    "X_test_vect3 = vect3.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy score</th>\n",
       "      <th>cv train score</th>\n",
       "      <th>cv test score</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "      <th>train-test gap</th>\n",
       "      <th>model status</th>\n",
       "      <th>bias vs variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.159091</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>underfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  accuracy score  \\\n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...            0.75   \n",
       "0  (ExtraTreeClassifier(class_weight=None, criter...            0.75   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...            0.75   \n",
       "0  MultinomialNB(alpha=1.0, class_prior=None, fit...            1.00   \n",
       "0  XGBClassifier(base_score=0.5, booster='gbtree'...            0.75   \n",
       "\n",
       "   cv train score  cv test score  train score  test score  train-test gap  \\\n",
       "0        0.711111       0.833333     0.909091        0.75        0.159091   \n",
       "0        0.755556       0.833333     1.000000        0.75        0.250000   \n",
       "0        0.466667       0.833333     1.000000        0.75        0.250000   \n",
       "0        0.644444       0.833333     1.000000        1.00        0.000000   \n",
       "0        0.644444       0.833333     1.000000        0.75        0.250000   \n",
       "\n",
       "  model status bias vs variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0     underfit    high variance  \n",
       "0      overfit    high variance  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = pd.DataFrame() # Instantiate the empty shell to hold the function\n",
    "models = [rf, et, ada, nb,xb]\n",
    "\n",
    "for i in models:\n",
    "    sm = sm.append(model_scores(i, X_train_vect, y_train, X_test_vect, y_test))\n",
    "sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>density</td>\n",
       "      <td>0.299103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>700</td>\n",
       "      <td>0.134577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>change</td>\n",
       "      <td>0.131114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>co</td>\n",
       "      <td>0.128369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2799</th>\n",
       "      <td>motor</td>\n",
       "      <td>0.109050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>increase</td>\n",
       "      <td>0.108200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>design</td>\n",
       "      <td>0.089586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292</th>\n",
       "      <td>prius</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>pleasantly</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3200</th>\n",
       "      <td>plummeting</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature      coef\n",
       "1250     density  0.299103\n",
       "154          700  0.134577\n",
       "830       change  0.131114\n",
       "901           co  0.128369\n",
       "2799       motor  0.109050\n",
       "2197    increase  0.108200\n",
       "1274      design  0.089586\n",
       "3292       prius  0.000000\n",
       "3195  pleasantly  0.000000\n",
       "3200  plummeting  0.000000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df = pd.DataFrame()\n",
    "feature_importance_df['feature'] = vect.get_feature_names()\n",
    "feature_importance_df['coef'] = xb.feature_importances_\n",
    "feature_importance_df.sort_values(by='coef', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy score</th>\n",
       "      <th>cv train score</th>\n",
       "      <th>cv test score</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "      <th>train-test gap</th>\n",
       "      <th>model status</th>\n",
       "      <th>bias vs variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>underfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  accuracy score  \\\n",
       "0  MultinomialNB(alpha=1.0, class_prior=None, fit...            1.00   \n",
       "0  XGBClassifier(base_score=0.5, booster='gbtree'...            0.75   \n",
       "\n",
       "   cv train score  cv test score  train score  test score  train-test gap  \\\n",
       "0        0.533333       0.833333          1.0        1.00            0.00   \n",
       "0        0.644444       0.833333          1.0        0.75            0.25   \n",
       "\n",
       "  model status bias vs variance  \n",
       "0     underfit    high variance  \n",
       "0      overfit    high variance  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = pd.DataFrame() # Instantiate the empty shell to hold the function\n",
    "models = [nb, xb]\n",
    "\n",
    "for i in models:\n",
    "    sm = sm.append(model_scores(i, X_train_vect2, y_train, X_test_vect2, y_test))\n",
    "sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>25 gross</td>\n",
       "      <td>0.334152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35933</th>\n",
       "      <td>vehicle week</td>\n",
       "      <td>0.333047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29222</th>\n",
       "      <td>right next</td>\n",
       "      <td>0.332802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00 deepak</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25308</th>\n",
       "      <td>plus would</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25303</th>\n",
       "      <td>plus powertrain</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25304</th>\n",
       "      <td>plus radar</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25305</th>\n",
       "      <td>plus side</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25306</th>\n",
       "      <td>plus vehicle</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25307</th>\n",
       "      <td>plus whatever</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               feature      coef\n",
       "657           25 gross  0.334152\n",
       "35933     vehicle week  0.333047\n",
       "29222       right next  0.332802\n",
       "0            00 deepak  0.000000\n",
       "25308       plus would  0.000000\n",
       "25303  plus powertrain  0.000000\n",
       "25304       plus radar  0.000000\n",
       "25305        plus side  0.000000\n",
       "25306     plus vehicle  0.000000\n",
       "25307    plus whatever  0.000000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDF \n",
    "feature_importance_df = pd.DataFrame()\n",
    "feature_importance_df['feature'] = vect2.get_feature_names()\n",
    "feature_importance_df['coef'] = xb.feature_importances_\n",
    "feature_importance_df.sort_values(by='coef', ascending=False).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "171px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
