{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Coefficient-on-the-features\" data-toc-modified-id=\"Coefficient-on-the-features-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Coefficient on the features</a></span></li><li><span><a href=\"#Model-Instantiation\" data-toc-modified-id=\"Model-Instantiation-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Model Instantiation</a></span></li><li><span><a href=\"#Model-prep-and-Train/Test-split\" data-toc-modified-id=\"Model-prep-and-Train/Test-split-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Model prep and Train/Test split</a></span></li><li><span><a href=\"#Model-Score\" data-toc-modified-id=\"Model-Score-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Model Score</a></span></li><li><span><a href=\"#Principal-Component-Analysis-(PCA)\" data-toc-modified-id=\"Principal-Component-Analysis-(PCA)-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Principal Component Analysis (PCA)</a></span></li><li><span><a href=\"#Telsa-Only\" data-toc-modified-id=\"Telsa-Only-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Telsa Only</a></span><ul class=\"toc-item\"><li><span><a href=\"#Principal-Component-Analysis-(PCA)-for-Tesla\" data-toc-modified-id=\"Principal-Component-Analysis-(PCA)-for-Tesla-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Principal Component Analysis (PCA) for Tesla</a></span></li></ul></li><li><span><a href=\"#Simple-Neural-Network\" data-toc-modified-id=\"Simple-Neural-Network-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Simple Neural Network</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import pandas_datareader as pdr\n",
    "\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingRegressor, VotingClassifier, RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier,   AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "from capstone_function import model_scores\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from capstone_function import model_scores\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modeling concern and model selection**\n",
    "- Before modeling, one of the concern is multicollinearity as some of features are highly correlated if we use linear regression to predict continuous values. Meanwhile, we can not guarantee the independence of each features because management and analyst may have a similar point of view or sentiment in the call transcripts. \n",
    "\n",
    "- However, referred to the setup of the problem statement, we want to predict either the market is up or down for speculative investors, classification model such as tree-based model, GBM-based model will work well in this dataset. Since we will use the combination of both, adding or removing correlated variables should not hit the accuracy scores but only decrease the computing time necessary. Since boosted trees use individual decision trees, they also are unaffected by multi-collinearity. \n",
    "\n",
    "- The ideal candidate will be Random forest and XGBoost for this data set. The importance matrix of an xgboost model is actually a data table object with the first column listing the names of all the features actually used in the boosted trees. The second column is the Gain metric which implies the relative contribution of the corresponding feature to the model calculated by taking each feature's contribution for each tree in the model. A higher value of this metric when compared to another feature implies it is more important for generating a prediction. Therefore, the ultimate goal will be providing insights to speculative investors on what to look for before next trading day. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "df = pickle.load(open( \"../data/df_final.pkl\", \"rb\" ))\n",
    "df = df.drop(columns=['Close','Open','pct_price'])\n",
    "df.drop_duplicates(subset='transcripts', keep='first', inplace=True)\n",
    "\n",
    "df = df.select_dtypes([np.number])\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coefficient on the features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pct_price_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pct_price_target</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>esp_target</th>\n",
       "      <td>0.185844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tx_QAflesch_reading_ease</th>\n",
       "      <td>0.137845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polarity</th>\n",
       "      <td>0.131189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tx_QA_compound</th>\n",
       "      <td>0.115045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjectivity</th>\n",
       "      <td>0.109585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transcriptsflesch_reading_ease</th>\n",
       "      <td>0.099037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tx_QA_polarity</th>\n",
       "      <td>0.097424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tx_QA_subjectivity</th>\n",
       "      <td>0.095725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tx_MDdale_chall_readability_score</th>\n",
       "      <td>0.088516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   pct_price_target\n",
       "pct_price_target                           1.000000\n",
       "esp_target                                 0.185844\n",
       "tx_QAflesch_reading_ease                   0.137845\n",
       "polarity                                   0.131189\n",
       "tx_QA_compound                             0.115045\n",
       "subjectivity                               0.109585\n",
       "transcriptsflesch_reading_ease             0.099037\n",
       "tx_QA_polarity                             0.097424\n",
       "tx_QA_subjectivity                         0.095725\n",
       "tx_MDdale_chall_readability_score          0.088516"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()[['pct_price_target']].sort_values(by='pct_price_target', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pct_price_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tx_MDtextstat.lexicon_count</th>\n",
       "      <td>-0.133579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transcriptsdale_chall_readability_score</th>\n",
       "      <td>-0.133712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tx_QAautomated_readability_index</th>\n",
       "      <td>-0.134759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tx_QAgunning_fog</th>\n",
       "      <td>-0.144407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tx_QAflesch_kincaid_grade</th>\n",
       "      <td>-0.148334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tx_QA_avg_sentence_length</th>\n",
       "      <td>-0.149017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tx_QAdale_chall_readability_score</th>\n",
       "      <td>-0.165917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volume</th>\n",
       "      <td>-0.171352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_price_target_same_day</th>\n",
       "      <td>-0.633531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_price_same_day</th>\n",
       "      <td>-0.634030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         pct_price_target\n",
       "tx_MDtextstat.lexicon_count                     -0.133579\n",
       "transcriptsdale_chall_readability_score         -0.133712\n",
       "tx_QAautomated_readability_index                -0.134759\n",
       "tx_QAgunning_fog                                -0.144407\n",
       "tx_QAflesch_kincaid_grade                       -0.148334\n",
       "tx_QA_avg_sentence_length                       -0.149017\n",
       "tx_QAdale_chall_readability_score               -0.165917\n",
       "Volume                                          -0.171352\n",
       "pct_price_target_same_day                       -0.633531\n",
       "pct_price_same_day                              -0.634030"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()[['pct_price_target']].sort_values(by='pct_price_target', ascending=False)[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate models \n",
    "logreg = LogisticRegression(random_state=42)\n",
    "dt = DecisionTreeClassifier()\n",
    "et = ExtraTreesClassifier(random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf1 = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gbrt1 = GradientBoostingRegressor(max_depth=5, n_estimators=3, learning_rate=1.0)\n",
    "\n",
    "svm = SVC(kernel='poly', degree=2)\n",
    "\n",
    "xb = xgb.XGBClassifier(random_state=42)\n",
    "xb1 = xgb.XGBClassifier(learning_rate =0.1,n_estimators=1000,max_depth=5,min_child_weight=1,gamma=0,subsample=0.8,colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',nthread=4,scale_pos_weight=1,seed=42)\n",
    "\n",
    "ada = AdaBoostClassifier(random_state=42)\n",
    "ada1 = AdaBoostClassifier (DecisionTreeClassifier(), n_estimators=10, learning_rate=1, random_state= 42 )\n",
    "\n",
    "bg = BaggingClassifier(DecisionTreeClassifier(), max_samples=0.5, max_features=1,n_estimators=10,random_state= 42 )\n",
    "\n",
    "#Emsenble model\n",
    "evc = VotingClassifier( estimators=[ ('lr',logreg), ('dt', dt), ('svm', svm),('et',et) ], voting='hard')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model prep and Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['pct_price_target','Volume'])\n",
    "y = df['pct_price_target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y, \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train) # must fit transform to numbers for train \n",
    "X_test_sc = ss.transform(X_test)       # must transform to number for test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy score</th>\n",
       "      <th>cv train score</th>\n",
       "      <th>cv test score</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "      <th>train-test gap</th>\n",
       "      <th>model status</th>\n",
       "      <th>bias vs variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.643452</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.624008</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.665476</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.601587</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC(C=1.0, cache_size=200, class_weight=None, ...</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.600397</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.295833</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.644841</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.668651</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VotingClassifier(estimators=[('lr', LogisticRe...</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.684921</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  accuracy score  \\\n",
       "0  LogisticRegression(C=1.0, class_weight=None, d...          0.5000   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...          0.3125   \n",
       "0  (ExtraTreeClassifier(class_weight=None, criter...          0.7500   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...          0.6250   \n",
       "0  ([DecisionTreeRegressor(criterion='friedman_ms...          0.6875   \n",
       "0  SVC(C=1.0, cache_size=200, class_weight=None, ...          0.4375   \n",
       "0  XGBClassifier(base_score=0.5, booster='gbtree'...          0.6250   \n",
       "0  XGBClassifier(base_score=0.5, booster='gbtree'...          0.6250   \n",
       "0  VotingClassifier(estimators=[('lr', LogisticRe...          0.5000   \n",
       "\n",
       "   cv train score  cv test score  train score  test score  train-test gap  \\\n",
       "0        0.638889       0.433333     1.000000      0.5000        0.500000   \n",
       "0        0.643452       0.388889     1.000000      0.3125        0.687500   \n",
       "0        0.624008       0.444444     1.000000      0.7500        0.250000   \n",
       "0        0.665476       0.566667     1.000000      0.6250        0.375000   \n",
       "0        0.601587       0.500000     1.000000      0.6875        0.312500   \n",
       "0        0.600397       0.500000     0.733333      0.4375        0.295833   \n",
       "0        0.644841       0.566667     1.000000      0.6250        0.375000   \n",
       "0        0.668651       0.566667     1.000000      0.6250        0.375000   \n",
       "0        0.684921       0.444444     1.000000      0.5000        0.500000   \n",
       "\n",
       "  model status bias vs variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_matrix = pd.DataFrame() # Instantiate the empty shell to hold the function\n",
    "\n",
    "models = [logreg, rf,et,ada,gb, svm, xb, xb1, evc]\n",
    "\n",
    "for i in models:\n",
    "    score_matrix = score_matrix.append(model_scores(i, X_train_sc, y_train, X_test_sc, y_test))\n",
    "score_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pct_price_target_same_day</td>\n",
       "      <td>0.255232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pct_price_same_day</td>\n",
       "      <td>0.090428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tx_QA_neg</td>\n",
       "      <td>0.045227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>tx_QAdifficult_words</td>\n",
       "      <td>0.032455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>transcriptsdale_chall_readability_score</td>\n",
       "      <td>0.029059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tx_MD_neg</td>\n",
       "      <td>0.028147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>transcriptsflesch_kincaid_grade</td>\n",
       "      <td>0.027838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>transcriptsdifficult_words</td>\n",
       "      <td>0.027101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tx_MD_subjectivity</td>\n",
       "      <td>0.023494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>tx_MDflesch_kincaid_grade</td>\n",
       "      <td>0.021928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    feature      coef\n",
       "7                 pct_price_target_same_day  0.255232\n",
       "3                        pct_price_same_day  0.090428\n",
       "14                                tx_QA_neg  0.045227\n",
       "51                     tx_QAdifficult_words  0.032455\n",
       "34  transcriptsdale_chall_readability_score  0.029059\n",
       "10                                tx_MD_neg  0.028147\n",
       "28          transcriptsflesch_kincaid_grade  0.027838\n",
       "29               transcriptsdifficult_words  0.027101\n",
       "22                       tx_MD_subjectivity  0.023494\n",
       "39                tx_MDflesch_kincaid_grade  0.021928"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df = pd.DataFrame()\n",
    "feature_importance_df['feature'] = X_train.columns\n",
    "feature_importance_df['coef'] = et.feature_importances_\n",
    "feature_importance_df.sort_values(by='coef', ascending=False, inplace=True)\n",
    "feature_importance_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 1]\n",
      " [3 7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.83      0.71         6\n",
      "           1       0.88      0.70      0.78        10\n",
      "\n",
      "   micro avg       0.75      0.75      0.75        16\n",
      "   macro avg       0.75      0.77      0.75        16\n",
      "weighted avg       0.78      0.75      0.75        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix  \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = et.predict(X_test_sc)  \n",
    "cm = confusion_matrix(y_test, y_pred)  \n",
    "\n",
    "print(cm)  \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the confusion matrix, we see that the classifier got the following results:\n",
    "- Out of the (horizontal sum of 6) actual instances of 'ham' (not spam), it predicted correctly 5 of them;\n",
    "- Out of the (horizontal sum of 10) total actual instances of spam, it predicted correctly 7 of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x109847828>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "y_pred_prob = et.predict_proba(X_test_sc)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# create plot\n",
    "plt.plot(fpr, tpr, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random guess')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.xlim([-0.02, 1])\n",
    "plt.ylim([0, 1.02])\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The explained variance ratio with 2 components is 0.99. It could produce 0.75 accuracy with Extra tree model, compare to models without PCA. One of the most important applications of PCA is for speeding up machine learning algorithms as I intent to increase the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62581597 0.37167878 0.00192235]\n",
      "[0.62581597 0.99749475 0.9994171 ]\n"
     ]
    }
   ],
   "source": [
    "# Results 3 Principal Components\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)  \n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train)  \n",
    "X_test_pca = pca.transform(X_test)  \n",
    "\n",
    "# Explained_variance Ration\n",
    "explained_variance = pca.explained_variance_ratio_  \n",
    "\n",
    "print(explained_variance[0:5])\n",
    "print (np.cumsum(explained_variance[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy score</th>\n",
       "      <th>cv train score</th>\n",
       "      <th>cv test score</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "      <th>train-test gap</th>\n",
       "      <th>model status</th>\n",
       "      <th>bias vs variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.643452</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.624008</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.665476</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.601587</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC(C=1.0, cache_size=200, class_weight=None, ...</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.600397</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.295833</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.644841</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.668651</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VotingClassifier(estimators=[('lr', LogisticRe...</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.684921</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  accuracy score  \\\n",
       "0  LogisticRegression(C=1.0, class_weight=None, d...          0.5000   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...          0.3125   \n",
       "0  (ExtraTreeClassifier(class_weight=None, criter...          0.7500   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...          0.6250   \n",
       "0  ([DecisionTreeRegressor(criterion='friedman_ms...          0.6875   \n",
       "0  SVC(C=1.0, cache_size=200, class_weight=None, ...          0.4375   \n",
       "0  XGBClassifier(base_score=0.5, booster='gbtree'...          0.6250   \n",
       "0  XGBClassifier(base_score=0.5, booster='gbtree'...          0.6250   \n",
       "0  VotingClassifier(estimators=[('lr', LogisticRe...          0.5000   \n",
       "\n",
       "   cv train score  cv test score  train score  test score  train-test gap  \\\n",
       "0        0.638889       0.433333     1.000000      0.5000        0.500000   \n",
       "0        0.643452       0.388889     1.000000      0.3125        0.687500   \n",
       "0        0.624008       0.444444     1.000000      0.7500        0.250000   \n",
       "0        0.665476       0.566667     1.000000      0.6250        0.375000   \n",
       "0        0.601587       0.500000     1.000000      0.6875        0.312500   \n",
       "0        0.600397       0.500000     0.733333      0.4375        0.295833   \n",
       "0        0.644841       0.566667     1.000000      0.6250        0.375000   \n",
       "0        0.668651       0.566667     1.000000      0.6250        0.375000   \n",
       "0        0.684921       0.500000     1.000000      0.5000        0.500000   \n",
       "\n",
       "  model status bias vs variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_matrix = pd.DataFrame() # Instantiate the empty shell to hold the function\n",
    "\n",
    "models = [logreg, rf,et,ada,gb, svm, xb, xb1, evc]\n",
    "\n",
    "for i in models:\n",
    "    score_matrix = score_matrix.append(model_scores(i, X_train_sc, y_train, X_test_sc, y_test))\n",
    "score_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 1]\n",
      " [3 7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.83      0.71         6\n",
      "           1       0.88      0.70      0.78        10\n",
      "\n",
      "   micro avg       0.75      0.75      0.75        16\n",
      "   macro avg       0.75      0.77      0.75        16\n",
      "weighted avg       0.78      0.75      0.75        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix  \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = et.predict(X_test_sc)  \n",
    "cm = confusion_matrix(y_test, y_pred)  \n",
    "\n",
    "print(cm)  \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the confusion matrix, we see that the classifier got the following results:\n",
    "- Out of the (horizontal sum of 6) actual instances of 'ham' (not spam), it predicted correctly 5 of them;\n",
    "- Out of the (horizontal sum of 10) total actual instances of spam, it predicted correctly 7 of them. Therefore, the chance of predicting market is up correctly is higher than that of market is down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telsa Only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While building up a model on one particular company (Tesla), the accuracy and train-test gap are lowest. However, it doesn't mean that it is correctly labeled the target because there are only 4 test set. It is not representative enough for investor to risk their money on the market due to the limited dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "df = pickle.load(open( \"../data/df_1.pkl\", \"rb\" ))\n",
    "df = df.drop(columns=['Close','Open','pct_price'])\n",
    "df.drop_duplicates(subset='transcripts', keep='first', inplace=True)\n",
    "\n",
    "df = df.select_dtypes([np.number])\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['pct_price_target','Volume'])\n",
    "y = df['pct_price_target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y, \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42)\n",
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train) # must fit transform to numbers for train \n",
    "X_test_sc = ss.transform(X_test)       # must transform to number for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy score</th>\n",
       "      <th>cv train score</th>\n",
       "      <th>cv test score</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "      <th>train-test gap</th>\n",
       "      <th>model status</th>\n",
       "      <th>bias vs variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>underfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>underfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>underfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>underfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  accuracy score  \\\n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...            1.00   \n",
       "0  (ExtraTreeClassifier(class_weight=None, criter...            0.75   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...            1.00   \n",
       "0  XGBClassifier(base_score=0.5, booster='gbtree'...            1.00   \n",
       "0  XGBClassifier(base_score=0.5, booster='gbtree'...            1.00   \n",
       "\n",
       "   cv train score  cv test score  train score  test score  train-test gap  \\\n",
       "0        0.444444            1.0     0.909091        1.00       -0.090909   \n",
       "0        0.361111            1.0     1.000000        0.75        0.250000   \n",
       "0        0.527778            1.0     1.000000        1.00        0.000000   \n",
       "0        0.444444            1.0     1.000000        1.00        0.000000   \n",
       "0        0.444444            1.0     1.000000        1.00        0.000000   \n",
       "\n",
       "  model status bias vs variance  \n",
       "0     underfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0     underfit    high variance  \n",
       "0     underfit    high variance  \n",
       "0     underfit    high variance  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_matrix = pd.DataFrame() # Instantiate the empty shell to hold the function\n",
    "\n",
    "models = [rf,et,ada, xb, xb1]\n",
    "\n",
    "for i in models:\n",
    "    score_matrix = score_matrix.append(model_scores(i, X_train_sc, y_train, X_test_sc, y_test))\n",
    "score_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>tx_MDcoleman_liau_index</td>\n",
       "      <td>0.494497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tx_MD_neg</td>\n",
       "      <td>0.159128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pct_volume</td>\n",
       "      <td>0.144896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rev_total_b</td>\n",
       "      <td>0.143217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tx_MD_pos</td>\n",
       "      <td>0.046582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tx_MD_subjectivity</td>\n",
       "      <td>0.005561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>polarity</td>\n",
       "      <td>0.005493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>tx_QAlinsear_write_formula</td>\n",
       "      <td>0.000550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>tx_MDflesch_kincaid_grade</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tx_MD_num_syl</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feature      coef\n",
       "43     tx_MDcoleman_liau_index  0.494497\n",
       "9                    tx_MD_neg  0.159128\n",
       "3                   pct_volume  0.144896\n",
       "2                  rev_total_b  0.143217\n",
       "10                   tx_MD_pos  0.046582\n",
       "21          tx_MD_subjectivity  0.005561\n",
       "17                    polarity  0.005493\n",
       "51  tx_QAlinsear_write_formula  0.000550\n",
       "38   tx_MDflesch_kincaid_grade  0.000075\n",
       "34               tx_MD_num_syl  0.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df = pd.DataFrame()\n",
    "feature_importance_df['feature'] = X_train.columns\n",
    "feature_importance_df['coef'] = xb.feature_importances_\n",
    "feature_importance_df.sort_values(by='coef', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 1]\n",
      " [0 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.75      0.75      0.75         4\n",
      "   macro avg       0.50      0.38      0.43         4\n",
      "weighted avg       1.00      0.75      0.86         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix  \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = et.predict(X_test_sc)  \n",
    "cm = confusion_matrix(y_test, y_pred)  \n",
    "\n",
    "print(cm)  \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis (PCA) for Tesla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.52800649e-01 2.46397280e-01 6.70685104e-04]\n",
      "[0.75280065 0.99919793 0.99986861]\n"
     ]
    }
   ],
   "source": [
    "# Results 5 Principal Components\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)  \n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train)  \n",
    "X_test_pca = pca.transform(X_test)  \n",
    "\n",
    "# Explained_variance Ration\n",
    "explained_variance = pca.explained_variance_ratio_  \n",
    "\n",
    "print(explained_variance[0:5])\n",
    "print (np.cumsum(explained_variance[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy score</th>\n",
       "      <th>cv train score</th>\n",
       "      <th>cv test score</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "      <th>train-test gap</th>\n",
       "      <th>model status</th>\n",
       "      <th>bias vs variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.022727</td>\n",
       "      <td>underfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>overfit</td>\n",
       "      <td>high variance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  accuracy score  \\\n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...            0.50   \n",
       "0  (ExtraTreeClassifier(class_weight=None, criter...            0.75   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...            0.75   \n",
       "0  XGBClassifier(base_score=0.5, booster='gbtree'...            0.75   \n",
       "0  XGBClassifier(base_score=0.5, booster='gbtree'...            0.50   \n",
       "\n",
       "   cv train score  cv test score  train score  test score  train-test gap  \\\n",
       "0        0.333333            1.0     1.000000        0.50        0.500000   \n",
       "0        0.361111            1.0     1.000000        0.75        0.250000   \n",
       "0        0.416667            1.0     1.000000        0.75        0.250000   \n",
       "0        0.333333            1.0     0.727273        0.75       -0.022727   \n",
       "0        0.444444            1.0     0.818182        0.50        0.318182   \n",
       "\n",
       "  model status bias vs variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0      overfit    high variance  \n",
       "0     underfit    high variance  \n",
       "0      overfit    high variance  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_matrix = pd.DataFrame() # Instantiate the empty shell to hold the function\n",
    "\n",
    "models = [rf,et,ada, xb, xb1]\n",
    "\n",
    "for i in models:\n",
    "    score_matrix = score_matrix.append(model_scores(i, X_train_pca, y_train, X_test_pca, y_test))\n",
    "score_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 1]\n",
      " [0 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.75      0.75      0.75         4\n",
      "   macro avg       0.50      0.38      0.43         4\n",
      "weighted avg       1.00      0.75      0.86         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix  \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = et.predict(X_test_pca)  \n",
    "cm = confusion_matrix(y_test, y_pred)  \n",
    "\n",
    "print(cm)  \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network doesn't provide any value to classify the output. It may attributed to two issues: \n",
    "\n",
    "1. The non-random part of the relationship between the input and output is too small compared to the random part (one could argue that stock prices are like this). I.e. the input are not sufficiently related to the output. There isnt an universal way to detect this as it depends on the nature of the data.\n",
    "2. Too much noise in the dataset as feature columns contains similar information that people are repeatedly talking in the call transcript\n",
    "3. The test and training size of is too small. \n",
    "\n",
    "Therefore, neural network may not be the solution for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "df = pickle.load(open( \"../data/df_final.pkl\", \"rb\" ))\n",
    "df = df.drop(columns=['Close','Open','pct_price'])\n",
    "df.drop_duplicates(subset='transcripts', keep='first', inplace=True)\n",
    "\n",
    "df = df.select_dtypes([np.number])\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['pct_price_target','Volume'])\n",
    "y = df['pct_price_target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y, \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/billyu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "# Number of features\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#hidden layers\n",
    "model.add(layers.Dense(5300, input_dim=input_dim, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(100, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dense(30, input_dim=input_dim, activation='relu'))\n",
    "\n",
    "#output layer\n",
    "model.add(layers.Dense(1, activation='sigmoid'))  #Dense should be 1 for the binary output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/billyu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 45 samples, validate on 16 samples\n",
      "Epoch 1/30\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 8.7238 - acc: 0.4000 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 0s 320us/step - loss: 6.0891 - acc: 0.6222 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 0s 781us/step - loss: 6.0891 - acc: 0.6222 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 0s 867us/step - loss: 6.0891 - acc: 0.6222 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 0s 560us/step - loss: 6.0891 - acc: 0.6222 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 0s 377us/step - loss: 6.0891 - acc: 0.6222 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 6.0891 - acc: 0.6222 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 8/30\n",
      "45/45 [==============================] - 0s 892us/step - loss: 6.0891 - acc: 0.6222 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 9/30\n",
      "45/45 [==============================] - 0s 745us/step - loss: 6.0891 - acc: 0.6222 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 10/30\n",
      "45/45 [==============================] - 0s 637us/step - loss: 6.0891 - acc: 0.6222 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 11/30\n",
      "45/45 [==============================] - 0s 592us/step - loss: 6.0891 - acc: 0.6222 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 12/30\n",
      "45/45 [==============================] - 0s 478us/step - loss: 6.0891 - acc: 0.6222 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 13/30\n",
      "45/45 [==============================] - 0s 522us/step - loss: 6.0891 - acc: 0.6222 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 14/30\n",
      "45/45 [==============================] - 0s 854us/step - loss: 6.0891 - acc: 0.6222 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 15/30\n",
      "45/45 [==============================] - 0s 664us/step - loss: 6.0891 - acc: 0.6222 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 16/30\n",
      "45/45 [==============================] - 0s 925us/step - loss: 6.0891 - acc: 0.6222 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 17/30\n",
      "45/45 [==============================] - 0s 491us/step - loss: 6.0891 - acc: 0.6222 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 18/30\n",
      "45/45 [==============================] - 0s 317us/step - loss: 6.0891 - acc: 0.6222 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 19/30\n",
      "45/45 [==============================] - 0s 434us/step - loss: 6.0891 - acc: 0.6222 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 20/30\n",
      "45/45 [==============================] - 0s 444us/step - loss: 6.0891 - acc: 0.6222 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 21/30\n",
      "45/45 [==============================] - 0s 332us/step - loss: 6.0891 - acc: 0.6222 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 22/30\n",
      "45/45 [==============================] - 0s 313us/step - loss: 6.0891 - acc: 0.6222 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 23/30\n",
      "45/45 [==============================] - 0s 535us/step - loss: 6.0891 - acc: 0.6222 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 24/30\n",
      "45/45 [==============================] - 0s 272us/step - loss: 6.0891 - acc: 0.6222 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 25/30\n",
      "45/45 [==============================] - 0s 316us/step - loss: 6.0891 - acc: 0.6222 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 26/30\n",
      "45/45 [==============================] - 0s 317us/step - loss: 6.0891 - acc: 0.6222 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 27/30\n",
      "45/45 [==============================] - 0s 342us/step - loss: 6.0891 - acc: 0.6222 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 28/30\n",
      "45/45 [==============================] - 0s 423us/step - loss: 6.0891 - acc: 0.6222 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 29/30\n",
      "45/45 [==============================] - 0s 545us/step - loss: 6.0891 - acc: 0.6222 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 30/30\n",
      "45/45 [==============================] - 0s 543us/step - loss: 6.0891 - acc: 0.6222 - val_loss: 10.0738 - val_acc: 0.3750\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "         epochs=30, \n",
    "         batch_size=128, \n",
    "         validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a3ab7e4a8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='Train loss') #the error (loss) is getting lower\n",
    "plt.plot(history.history['val_loss'], label='Test loss') #the error (loss) is getting lower\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a1bac0160>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'], label='Train accuracy')\n",
    "plt.plot(history.history['val_acc'], label='Test accuracy')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
